{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVsw1sgj0KtO"
      },
      "source": [
        "# Automatic Waste Segregator: CNN for Real-World Application\n",
        "This Notebook assumed pre-knowledge about how CNN works, Numpy, Pandas and how to code a basic CNN for classifying MNIST Numbers. The matplotlib functions have self-explanatory names and do not need much delving into"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuwe59r5hPAQ",
        "outputId": "436fee88-324c-4986-a4df-c105aeeb1999"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'AWS'...\n",
            "remote: Enumerating objects: 2704, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (72/72), done.\u001b[K\n",
            "remote: Total 2704 (delta 76), reused 149 (delta 76), pack-reused 2555\u001b[K\n",
            "Receiving objects: 100% (2704/2704), 493.13 MiB | 22.28 MiB/s, done.\n",
            "Resolving deltas: 100% (79/79), done.\n",
            "Updating files: 100% (2427/2427), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/RishiNandha/AWS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q5mmb3LUhtEP"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, Dropout, SpatialDropout2D, AveragePooling2D\n",
        "import numpy as np\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imread, show, imshow\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "os.chdir('AWS')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCe3SxAYjQjA"
      },
      "source": [
        "## Dataset Preprocessing\n",
        "This is where we prepare the Training Set and the Validation Set\n",
        "\n",
        "### Challenges in any Real-World CNN Application\n",
        "\n",
        "We have a dataset of 1995 Images. This has two challenges:\n",
        "\n",
        "1. We cannot load the entire data into one numpy array in one shot. This will require the computer to allocate RAM to Python in the order of GBs\n",
        "\n",
        "2. 1995 Datapoints is a very small number to get good accuracies from.\n",
        "\n",
        "### 1. Lazy-Loading\n",
        "\n",
        "The first challenged is solved by \"Lazy-Loading\" the data. That is, the Data isn't loaded into a Numpy Array at the start of the program itself, instead we define a `flow_from_directory()` which takes the images from the given folder only when required.\n",
        "\n",
        "The folder has to have subfolders with names corresponding to the Class of the image, with images inside these subfolders\n",
        "\n",
        "### 2. Data Augmentation\n",
        "\n",
        "The second challenge is mitigate by randomizing transformations on the existing images to form new images. For example, a cat's image slightly rotated is still a cat. This is done using `ImageDataGenerator()`.\n",
        "\n",
        "Note that these transforms should be done only to a sensible extent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8PD4l5fjWi2",
        "outputId": "56dbf4d5-5c58-4d65-bcbd-174f0447fc07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1995 images belonging to 6 classes.\n"
          ]
        }
      ],
      "source": [
        "# Data Augmentation\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "   \tshear_range=0.1,\theight_shift_range=0.2,\n",
        "        zoom_range=0.2,     horizontal_flip=True,\n",
        "        vertical_flip=True, width_shift_range=0.2)\n",
        "\n",
        "# Lazy Loading\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'train',           target_size=(256, 256),\n",
        "        batch_size=16,      class_mode='categorical')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuhNXqzDrZSW"
      },
      "source": [
        "### 3. Validation Split\n",
        "Having a Validation Set other than just Training and Testing is important. This is because adding Validation Accuracy as a Metric allows us to track for Underfitting and Overfitting. This also allows us to set an arbitrarily large number of Epochs and \"Checkpoint the Training\" & \"Early Stop the Training\" (Discussed later)\n",
        "\n",
        "**Underfitting** - Both Training accuracy and Validation accuracy saturate to a small value\n",
        "\n",
        "**Overfitting** - Training accuracy gets unrealistically good but the Validation accuracy either stops increasing or starts decreasing\n",
        "\n",
        "There are pre-defined methods to do the Validation Split too but below is a demonstration of how to manually prepare a dataset. The output layer predicts a numpy array of probabilities, so the ideal predictions that we train the model to should be numpy arrays with `1` in the index corresponding to the right class and `0` everywhere else, length matched with the size of the output layer\n",
        "\n",
        "\n",
        "The pre-defined method would be much faster than this ofcourse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HJoVWEcBrX13",
        "outputId": "8c66cdb0-9881-4e81-cd42-6c6aac6757f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(406, 256, 256, 3) \t (406, 6)\n"
          ]
        }
      ],
      "source": [
        "# os.chdir() sets the current folder\n",
        "os.chdir('predb')\n",
        "\n",
        "# Empty Numpy Arrays initialized to start appending data into\n",
        "\n",
        "y_val = np.array([]).reshape((0,6))\n",
        "x_val = np.array([]).reshape((0,256,256,3))\n",
        "\n",
        "# Encoding in the right format to be matched against Output Layer\n",
        "\n",
        "def encode_class(x):\n",
        "\tl = [0 for i in range(6)]\n",
        "\tl[x]=1\n",
        "\treturn np.array(l).reshape((1,6))\n",
        "\n",
        "def load_data(name):\n",
        "\tglobal x_val\n",
        "\tglobal y_val\n",
        "\n",
        "    # x = 5 for \"Mixed\"\n",
        "\n",
        "\tx=5\n",
        "\n",
        "    # Re-sizing Images to match Input Layer\n",
        "\n",
        "\timage = plt.imread(name)\n",
        "\timage = cv2.resize(image,(256,256))\n",
        "\n",
        "\tx_val = np.append(x_val, image.reshape((1,256,256,3)),axis=0)\n",
        "\n",
        "    # In the predb folder, images have been named according to their classes.\n",
        "    # So this is checking if the class names are a substring of filename\n",
        "\n",
        "\tif 'cardboard' in name:\n",
        "\t\tx=0\n",
        "\telif 'glass' in name:\n",
        "\t\tx=1\n",
        "\telif 'metal' in name:\n",
        "\t\tx=2\n",
        "\telif 'paper' in name:\n",
        "\t\tx=3\n",
        "\telif 'plastic' in name:\n",
        "\t\tx=4\n",
        "\n",
        "\ty_val = np.append(y_val, encode_class(x),axis=0)\n",
        "\n",
        "# os.listdir() lists all filenames and folders in the current folder\n",
        "\n",
        "for i in os.listdir()[1:]:\n",
        "\tload_data(i)\n",
        "\n",
        "print(x_val.shape, '\\t', y_val.shape)\n",
        "os.chdir(\"..\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNim3eEIjJHz"
      },
      "source": [
        "## Model Definition\n",
        "This is where the educated guessing of what works goes.\n",
        "\n",
        "**Underfit:** We can either increase the number of layers or increase the size of layers or decrease the learning rate\n",
        "\n",
        "**Overfit:** We can either decrease the number of layers or decrease the size of layers or add dropout layers if its over-fitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2SEWjTbhiKwX"
      },
      "outputs": [],
      "source": [
        "# Model\n",
        "\n",
        "# Rishi's Model\n",
        "layerz = [Conv2D(72, kernel_size=(3,3), input_shape=(256,256,3)),\n",
        "\t\tConv2D(72, kernel_size=(3,3),activation='relu'),\n",
        "\t\tMaxPooling2D(pool_size=(2,2)),\n",
        "\t\tConv2D(72, kernel_size=(3,3)),\n",
        "\t\tConv2D(72, kernel_size=(3,3),activation='relu'),\n",
        "\t\tMaxPooling2D(pool_size=(2,2)),\n",
        "\t\tConv2D(72, kernel_size=(3,3)),\n",
        "\t\tConv2D(72, kernel_size=(3,3),activation='relu'),\n",
        "\t\tMaxPooling2D(pool_size=(2,2)),\n",
        "\t\tFlatten(),\n",
        "\t\tDense(250, activation='relu'),\n",
        "\t\tDense(6,activation='softmax')]\n",
        "\n",
        "# AM's model\n",
        "# layerz = [Conv2D(128,(3,3),input_shape=(256,256,3), activation='relu'),\n",
        "# \t\tMaxPooling2D(pool_size=2),\n",
        "# \t\tConv2D(32,(3,3),activation='relu'),\n",
        "# \t\tMaxPooling2D(pool_size=2),\n",
        "# \t\tFlatten(),\n",
        "# \t\tDense(512,activation='relu'),\n",
        "# \t\tDropout(0.2),\n",
        "# \t\tDense(6,activation='softmax')]\n",
        "\n",
        "model=keras.Sequential(layerz)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(learning_rate=0.0000025*18), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikR0VdXVwb2D"
      },
      "source": [
        "## Training Callbacks\n",
        "The two useful training callbacks we mentioned earlier are \"Checkpoint\" and \"Early Stopping\"\n",
        "\n",
        "### 1. Checkpoint\n",
        "\n",
        "The model can be asked to save the best weights that's been encounter so far into a `hdf5` file. \"Best\" is decided using the validation accuracy.\n",
        "\n",
        "This allows the model to save only up until where the training is still favourable and ignores the changes once over-fitting starts.\n",
        "\n",
        "This also allows to repeatly run the same code to train further using a `try:` statement whenever a `hdf5` file already exists\n",
        "\n",
        "### 2. Early Stopping\n",
        "\n",
        "The model can be asked to stop training after waiting for a `patience`-number of epochs. This is done so that the program stops after underfitting or overfitting starts and doesn't waste time running for more"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "q0M390DfiuzO",
        "outputId": "70b5d553-2027-4a12-d7b7-3790dc820e7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No Pre-existing Checkpoint, creating new one\n"
          ]
        }
      ],
      "source": [
        "# Checkpoint\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint('ckpt.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "# Early Stopping\n",
        "\n",
        "stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "\n",
        "try:\n",
        "    model.load_weights('ckpt.hdf5')\n",
        "except:\n",
        "    print(\"No Pre-existing Checkpoint, creating new one\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTDk1zPUzlwW"
      },
      "source": [
        "## Training\n",
        "\n",
        "Finally, here goes Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qi_rAtNbzrIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44f64c75-11bf-4bd2-c830-b0c3efabaa56"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "110/110 [==============================] - ETA: 0s - loss: 7.0555 - accuracy: 0.3305\n",
            "Epoch 1: val_accuracy improved from -inf to 0.45074, saving model to ckpt.hdf5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 60s 437ms/step - loss: 7.0555 - accuracy: 0.3305 - val_loss: 1.4420 - val_accuracy: 0.4507\n",
            "Epoch 2/100\n",
            "110/110 [==============================] - ETA: 0s - loss: 1.4034 - accuracy: 0.4222\n",
            "Epoch 2: val_accuracy did not improve from 0.45074\n",
            "110/110 [==============================] - 33s 302ms/step - loss: 1.4034 - accuracy: 0.4222 - val_loss: 1.3883 - val_accuracy: 0.4507\n",
            "Epoch 3/100\n",
            "110/110 [==============================] - ETA: 0s - loss: 1.3580 - accuracy: 0.4644\n",
            "Epoch 3: val_accuracy improved from 0.45074 to 0.49507, saving model to ckpt.hdf5\n",
            "110/110 [==============================] - 35s 315ms/step - loss: 1.3580 - accuracy: 0.4644 - val_loss: 1.2140 - val_accuracy: 0.4951\n",
            "Epoch 4/100\n",
            "101/110 [==========================>...] - ETA: 2s - loss: 1.2806 - accuracy: 0.4898"
          ]
        }
      ],
      "source": [
        "model.fit(\n",
        "        train_generator, steps_per_epoch=1995//18,\n",
        "        epochs=100, validation_data=(x_val,y_val), callbacks=[checkpoint, stop])\n",
        "\n",
        "model.save(\"AWS\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5HnAZ7z03k6"
      },
      "source": [
        "## Showtime: Testing\n",
        "Here's a loop that picks an image, shows what it is and then runs the model on it. `model(img)` just sends the `img` through the model as if `model()` was a function and returns the output layer's values as a numpy array. Rest of the code is just formatting it for displaying"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXNd-TKP09od"
      },
      "outputs": [],
      "source": [
        "l=[\"Cardboard\", \"Glass\", \"Metal\", \"Paper\", \"Plastic\", \"Mixed\"]\n",
        "\n",
        "flag = 1\n",
        "os.chdir('predb')\n",
        "dirlist=os.listdir()\n",
        "print(' ')\n",
        "while flag==1:\n",
        "\n",
        "\t# Open Image and Directory\n",
        "\timgdir=dirlist[int(input(\"\\nEnter Test Image Index (Enter an Integer lesser than \"+str(len(dirlist))+\") : \"))]\n",
        "\timg = imread(imgdir)\n",
        "\n",
        "\t# Display Image\n",
        "\timshow(img)\n",
        "\tshow()\n",
        "\n",
        "\t# Run Image Through CNN\n",
        "\timg = resize(img,(256,256))\n",
        "\timg = img.reshape((1,256,256,3))\n",
        "\timg = model.predict(img,verbose=0)\n",
        "\timg=img.reshape((6,))\n",
        "\n",
        "\t# Correct Class\n",
        "\tprint(\"\\nCorrect Class :\", imgdir)\n",
        "\n",
        "\t# Prediction by CNN\n",
        "\tif np.amax(img)<(2.0/3):\n",
        "\t\tprint(\"\\nPredicted Class : Mixed\")\n",
        "\t\tprint(\"Confidence was too low, hence it's precautiously categorized under Mixed\")\n",
        "\telse:\n",
        "\t\tprint(\"\\nPredicted Class :\",l[int(np.where(img == np.amax(img))[0][0])])\n",
        "\t\tprint(\"Confidence :\",(np.amax(img)*100)//1, \"%\")\n",
        "\n",
        "\tflag=int(input(\"\\n\\nContinue? (1/0) : \"))\n",
        "\n",
        "\tprint(\"\\n----------------------------------------------------------------------------------------------------------------------\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}